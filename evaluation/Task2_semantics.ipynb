{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosineSimilarity(v1,v2):\n",
    "    return np.dot(v1,v2)/math.sqrt(np.dot(v1,v1)*np.dot(v2,v2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = open(\"../pickles/vocab.pickle\",\"rb\")\n",
    "vocabulary = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"../pickles/word2id.pickle\",\"rb\")\n",
    "word2idx = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"../pickles/id2word.pickle\",\"rb\")\n",
    "idx2word = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"../pickles/embedding.pickle\",\"rb\")\n",
    "W = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "brothers sisters he she\n",
      "that\n",
      "brothers sisters his her\n",
      "spending\n",
      "brothers sisters king queen\n",
      "spending\n",
      "he she his her\n",
      "yeutter\n",
      "he she king queen\n",
      "reviewing\n",
      "he she brothers sisters\n",
      "energy\n",
      "his her king queen\n",
      "asked\n",
      "his her brothers sisters\n",
      "estimates\n",
      "his her he she\n",
      "another\n",
      "king queen brothers sisters\n",
      "banking\n",
      "king queen he she\n",
      "officials\n",
      "king queen his her\n",
      "issues\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "filenames=['all_capitals','capital_common_countries','city_state','currency','family']\n",
    "total=0\n",
    "total_Entries=0\n",
    "correct=0\n",
    "for j in range(len(filenames)):\n",
    "\n",
    "    df=pd.read_csv('../data/'+filenames[j]+'.txt',sep=\" \")\n",
    "    df=np.array(df)\n",
    "    #print (df.head)\n",
    "    for w1,w2,w3,w4 in df:\n",
    "        total_Entries=total_Entries+1\n",
    "        if w1 in vocabulary and w2 in vocabulary and w3 in vocabulary and w4 in vocabulary:\n",
    "            print(w1,w2,w3,w4)\n",
    "            w1=w1.lower()\n",
    "            w2=w2.lower()\n",
    "            w3=w3.lower()\n",
    "            w4=w4.lower()\n",
    "            total=total+1\n",
    "            v=W[word2idx[w1]]-W[word2idx[w2]]+W[word2idx[w3]]\n",
    "            max_similarity=-2\n",
    "            max_similar=0\n",
    "            for i in range(len(vocabulary)):\n",
    "                if cosineSimilarity(v,W[i])>max_similarity and idx2word[i]!=\",\" and idx2word[i]!=\".\" and idx2word[i]!=\"!\" and idx2word[i]!='?' and idx2word[i]!=w1 and idx2word[i]!=w2 and idx2word[i]!=w3:\n",
    "                    max_similar=i\n",
    "                    max_similarity=cosineSimilarity(v,W[i])\n",
    "            if idx2word[max_similar]==w4:\n",
    "                correct=correct+1\n",
    "            print(idx2word[max_similar])\n",
    "\n",
    "\n",
    "print(correct/total)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
